{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e611239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "lines=pd.read_csv(r\"English_to_Roman_Urdu changes data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c0dd847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>urdu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how is things?</td>\n",
       "      <td>cheezein kesi hain?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how is life?</td>\n",
       "      <td>zindagi kesi chal rahi?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is happening?</td>\n",
       "      <td>kiya horaha&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is going on?</td>\n",
       "      <td>kiya chalraha?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hey there!</td>\n",
       "      <td>arey haan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>what is up?</td>\n",
       "      <td>aur kiya horaha hai?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>good mornng</td>\n",
       "      <td>subah bakhair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>good day</td>\n",
       "      <td>acha din</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>good afternoon</td>\n",
       "      <td>dopehr bakahir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>good evening</td>\n",
       "      <td>sham bakhair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>good night</td>\n",
       "      <td>shab bakhair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pleased to meet you</td>\n",
       "      <td>app se mil kar nihayat khushi hwi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>it is a pleasure to meet you</td>\n",
       "      <td>app se mil kar acha laga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>how do you do?</td>\n",
       "      <td>app kese hain?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>how are you doing?</td>\n",
       "      <td>app kese hain?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>how have you been?</td>\n",
       "      <td>app kese rahe?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>it is nice to meet you</td>\n",
       "      <td>app se mil kar acha laga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>how is it going?</td>\n",
       "      <td>kesa chal raha hai?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>how are you going?</td>\n",
       "      <td>app kese ja rahe hain?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nice to see you</td>\n",
       "      <td>app ko dekh ke acha laga</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             eng                               urdu\n",
       "0                 how is things?                cheezein kesi hain?\n",
       "1                   how is life?            zindagi kesi chal rahi?\n",
       "2             what is happening?                       kiya horaha>\n",
       "3              what is going on?                     kiya chalraha?\n",
       "4                     hey there!                          arey haan\n",
       "5                    what is up?               aur kiya horaha hai?\n",
       "6                    good mornng                      subah bakhair\n",
       "7                       good day                           acha din\n",
       "8                 good afternoon                     dopehr bakahir\n",
       "9                   good evening                       sham bakhair\n",
       "10                    good night                       shab bakhair\n",
       "11           pleased to meet you  app se mil kar nihayat khushi hwi\n",
       "12  it is a pleasure to meet you           app se mil kar acha laga\n",
       "13                how do you do?                     app kese hain?\n",
       "14            how are you doing?                     app kese hain?\n",
       "15            how have you been?                     app kese rahe?\n",
       "16        it is nice to meet you           app se mil kar acha laga\n",
       "17              how is it going?                kesa chal raha hai?\n",
       "18            how are you going?             app kese ja rahe hain?\n",
       "19               nice to see you           app ko dekh ke acha laga"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b368134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22aa5362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>urdu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>alright mate</td>\n",
       "      <td>START_ sab theak dost _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>hey there</td>\n",
       "      <td>START_ arey haan _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>whats going on</td>\n",
       "      <td>START_ kiya horaha hai _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>lovely to see you</td>\n",
       "      <td>START_ app ko dekh kar acha laga _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>how is things</td>\n",
       "      <td>START_ cheezein kesi hain _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>hi there</td>\n",
       "      <td>START_ hi haan _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>good afternoon</td>\n",
       "      <td>START_ dopehr bakahir _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>hows it going</td>\n",
       "      <td>START_ kesa chal raha hai _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>good to see you</td>\n",
       "      <td>START_ tumhe dekh kar acha laga _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>hows it going</td>\n",
       "      <td>START_ kesa chal raha hai _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   eng                                   urdu\n",
       "249       alright mate             START_ sab theak dost _END\n",
       "226          hey there                  START_ arey haan _END\n",
       "69      whats going on            START_ kiya horaha hai _END\n",
       "136  lovely to see you  START_ app ko dekh kar acha laga _END\n",
       "222      how is things         START_ cheezein kesi hain _END\n",
       "254           hi there                    START_ hi haan _END\n",
       "230     good afternoon             START_ dopehr bakahir _END\n",
       "79       hows it going         START_ kesa chal raha hai _END\n",
       "132    good to see you   START_ tumhe dekh kar acha laga _END\n",
       "190      hows it going         START_ kesa chal raha hai _END"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercase all characters\n",
    "lines.eng=lines.eng.apply(lambda x: x.lower())\n",
    "lines.urdu=lines.urdu.apply(lambda x: x.lower())\n",
    "\n",
    "# Remove quotes\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines.urdu=lines.urdu.apply(lambda x: re.sub(\"'\", '', x))\n",
    "\n",
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "\n",
    "# Remove all the special characters\n",
    "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines.urdu=lines.urdu.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "# Remove extra spaces\n",
    "lines.eng=lines.eng.apply(lambda x: x.strip())\n",
    "lines.urdu=lines.urdu.apply(lambda x: x.strip())\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.urdu=lines.urdu.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "\n",
    "# Add start and end tokens to target sequences\n",
    "lines.urdu = lines.urdu.apply(lambda x : 'START_ '+ x + ' _END')\n",
    "\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d2c3367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Source Length: 9\n",
      "Max Target Lenght: 11\n",
      "Max Source Length: 9\n",
      "Max Target Lenght: 11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Vocabulary of English\n",
    "all_eng_words=set()# Max Length of source sequence\n",
    "lenght_list=[]\n",
    "for l in lines.eng:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_src = np.max(lenght_list)\n",
    "print('Max Source Length:',max_length_src)\n",
    "\n",
    "# Max Length of target sequence\n",
    "lenght_list=[]\n",
    "for l in lines.urdu:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_tar = np.max(lenght_list)\n",
    "print('Max Target Lenght:',max_length_tar)\n",
    "for eng in lines.eng:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "# Vocabulary of Urdu \n",
    "all_urdu_words=set()\n",
    "for urdu in lines.urdu:\n",
    "    for word in urdu.split():\n",
    "        if word not in all_urdu_words:\n",
    "            all_urdu_words.add(word)# Max Length of source sequence\n",
    "lenght_list=[]\n",
    "for l in lines.eng:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_src = np.max(lenght_list)\n",
    "print('Max Source Length:',max_length_src)\n",
    "\n",
    "# Max Length of target sequence\n",
    "lenght_list=[]\n",
    "for l in lines.urdu:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_tar = np.max(lenght_list)\n",
    "print('Max Target Lenght:',max_length_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8962243b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 153)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_urdu_words))\n",
    "num_encoder_tokens = len(all_eng_words)+1\n",
    "num_decoder_tokens = len(all_urdu_words)+1\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8409c0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_decoder_tokens += 1 # For zero padding\n",
    "num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0012af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>urdu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>i wish you all the best</td>\n",
       "      <td>START_ mai apke lye naik khuwahishaat rakhta h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>how is your day</td>\n",
       "      <td>START_ app ka din kesa hai _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>i am happy to see you again</td>\n",
       "      <td>START_ mai apko dobara dekh ke khush hun _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>what’s up</td>\n",
       "      <td>START_ kiya chal raha hai _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>have fun</td>\n",
       "      <td>START_ mazey karo _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>can i stay here</td>\n",
       "      <td>START_ kiya mein yahan reh sakta hun _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>break a leg</td>\n",
       "      <td>START_ tang khechna _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>how are you doing</td>\n",
       "      <td>START_ app kese hain _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>im glad to see you again</td>\n",
       "      <td>START_ mai app ko dobara dekh kar khush hun _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>hi there</td>\n",
       "      <td>START_ hi haan _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             eng  \\\n",
       "61       i wish you all the best   \n",
       "35               how is your day   \n",
       "52   i am happy to see you again   \n",
       "93                     what’s up   \n",
       "287                     have fun   \n",
       "101              can i stay here   \n",
       "288                  break a leg   \n",
       "14             how are you doing   \n",
       "265     im glad to see you again   \n",
       "32                      hi there   \n",
       "\n",
       "                                                  urdu  \n",
       "61   START_ mai apke lye naik khuwahishaat rakhta h...  \n",
       "35                     START_ app ka din kesa hai _END  \n",
       "52       START_ mai apko dobara dekh ke khush hun _END  \n",
       "93                      START_ kiya chal raha hai _END  \n",
       "287                             START_ mazey karo _END  \n",
       "101          START_ kiya mein yahan reh sakta hun _END  \n",
       "288                           START_ tang khechna _END  \n",
       "14                           START_ app kese hain _END  \n",
       "265   START_ mai app ko dobara dekh kar khush hun _END  \n",
       "32                                 START_ hi haan _END  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "\n",
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\n",
    "\n",
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeb512bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((299,), (34,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train - Test Split\n",
    "X, y = lines.eng, lines.urdu\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "729b1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the train and test dataframes for reproducing the results later, as they are shuffled.\n",
    "\n",
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79a9d726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 64):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7b57f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 1\n",
    "epochs = 50\n",
    "latent_dim = 256\n",
    "print(train_samples//batch_size)\n",
    "print(val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37353e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26bcfc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8bd22bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "504cdb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2720069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "299/299 [==============================] - 40s 66ms/step - loss: 3.8975 - acc: 0.2249 - val_loss: 3.2465 - val_acc: 0.2457\n",
      "Epoch 2/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 3.0931 - acc: 0.3308 - val_loss: 2.6037 - val_acc: 0.4114\n",
      "Epoch 3/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 2.4809 - acc: 0.4321 - val_loss: 2.1075 - val_acc: 0.5143\n",
      "Epoch 4/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 1.9708 - acc: 0.5258 - val_loss: 1.8050 - val_acc: 0.5771\n",
      "Epoch 5/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 1.5099 - acc: 0.6209 - val_loss: 1.4979 - val_acc: 0.6571\n",
      "Epoch 6/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 1.1377 - acc: 0.7181 - val_loss: 1.2401 - val_acc: 0.7371\n",
      "Epoch 7/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.8316 - acc: 0.8043 - val_loss: 1.0374 - val_acc: 0.7829\n",
      "Epoch 8/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.6002 - acc: 0.8675 - val_loss: 0.8603 - val_acc: 0.7943\n",
      "Epoch 9/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.4223 - acc: 0.9117 - val_loss: 0.6181 - val_acc: 0.8457\n",
      "Epoch 10/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.2910 - acc: 0.9443 - val_loss: 0.4618 - val_acc: 0.8914\n",
      "Epoch 11/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.2052 - acc: 0.9579 - val_loss: 0.3367 - val_acc: 0.9200\n",
      "Epoch 12/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.1600 - acc: 0.9599 - val_loss: 0.3221 - val_acc: 0.9371\n",
      "Epoch 13/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.1263 - acc: 0.9728 - val_loss: 0.2548 - val_acc: 0.9486\n",
      "Epoch 14/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.1126 - acc: 0.9749 - val_loss: 0.1598 - val_acc: 0.9771\n",
      "Epoch 15/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.1013 - acc: 0.9796 - val_loss: 0.1511 - val_acc: 0.9657\n",
      "Epoch 16/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.0958 - acc: 0.9789 - val_loss: 0.1374 - val_acc: 0.9714\n",
      "Epoch 17/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.0932 - acc: 0.9783 - val_loss: 0.1308 - val_acc: 0.9771\n",
      "Epoch 18/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.0903 - acc: 0.9789 - val_loss: 0.1249 - val_acc: 0.9771\n",
      "Epoch 19/50\n",
      "299/299 [==============================] - 13s 45ms/step - loss: 0.0883 - acc: 0.9796 - val_loss: 0.1199 - val_acc: 0.9771\n",
      "Epoch 20/50\n",
      "299/299 [==============================] - 13s 45ms/step - loss: 0.0865 - acc: 0.9789 - val_loss: 0.1168 - val_acc: 0.9771\n",
      "Epoch 21/50\n",
      "299/299 [==============================] - 13s 45ms/step - loss: 0.0851 - acc: 0.9796 - val_loss: 0.1139 - val_acc: 0.9771\n",
      "Epoch 22/50\n",
      "299/299 [==============================] - 13s 45ms/step - loss: 0.0845 - acc: 0.9796 - val_loss: 0.1109 - val_acc: 0.9771\n",
      "Epoch 23/50\n",
      "299/299 [==============================] - 13s 45ms/step - loss: 0.0827 - acc: 0.9789 - val_loss: 0.1100 - val_acc: 0.9771\n",
      "Epoch 24/50\n",
      "299/299 [==============================] - 13s 45ms/step - loss: 0.0818 - acc: 0.9789 - val_loss: 0.1090 - val_acc: 0.9771\n",
      "Epoch 25/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.0809 - acc: 0.9796 - val_loss: 0.1079 - val_acc: 0.9771\n",
      "Epoch 26/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.0801 - acc: 0.9796 - val_loss: 0.1068 - val_acc: 0.9771\n",
      "Epoch 27/50\n",
      "299/299 [==============================] - 14s 45ms/step - loss: 0.0793 - acc: 0.9803 - val_loss: 0.1062 - val_acc: 0.9771\n",
      "Epoch 28/50\n",
      "299/299 [==============================] - 13s 45ms/step - loss: 0.0790 - acc: 0.9803 - val_loss: 0.1053 - val_acc: 0.9771\n",
      "Epoch 29/50\n",
      "299/299 [==============================] - 13s 45ms/step - loss: 0.0782 - acc: 0.9803 - val_loss: 0.1056 - val_acc: 0.9771\n",
      "Epoch 30/50\n",
      "299/299 [==============================] - 13s 45ms/step - loss: 0.0776 - acc: 0.9796 - val_loss: 0.1057 - val_acc: 0.9771\n",
      "Epoch 31/50\n",
      "299/299 [==============================] - 13s 45ms/step - loss: 0.0772 - acc: 0.9789 - val_loss: 0.1057 - val_acc: 0.9771\n",
      "Epoch 32/50\n",
      "299/299 [==============================] - 13s 45ms/step - loss: 0.0769 - acc: 0.9789 - val_loss: 0.1058 - val_acc: 0.9771\n",
      "Epoch 33/50\n",
      "299/299 [==============================] - 13s 45ms/step - loss: 0.0765 - acc: 0.9789 - val_loss: 0.1058 - val_acc: 0.9771\n",
      "Epoch 34/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.0763 - acc: 0.9789 - val_loss: 0.1060 - val_acc: 0.9771\n",
      "Epoch 35/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.0760 - acc: 0.9789 - val_loss: 0.1063 - val_acc: 0.9771\n",
      "Epoch 36/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.0758 - acc: 0.9789 - val_loss: 0.1067 - val_acc: 0.9771\n",
      "Epoch 37/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.0755 - acc: 0.9789 - val_loss: 0.1068 - val_acc: 0.9771\n",
      "Epoch 38/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.0751 - acc: 0.9789 - val_loss: 0.1068 - val_acc: 0.9771\n",
      "Epoch 39/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.0747 - acc: 0.9789 - val_loss: 0.1064 - val_acc: 0.9771\n",
      "Epoch 40/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.0743 - acc: 0.9789 - val_loss: 0.1060 - val_acc: 0.9771\n",
      "Epoch 41/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.0739 - acc: 0.9789 - val_loss: 0.1058 - val_acc: 0.9771\n",
      "Epoch 42/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.0736 - acc: 0.9789 - val_loss: 0.1058 - val_acc: 0.9771\n",
      "Epoch 43/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.0732 - acc: 0.9789 - val_loss: 0.1056 - val_acc: 0.9771\n",
      "Epoch 44/50\n",
      "299/299 [==============================] - 14s 46ms/step - loss: 0.0728 - acc: 0.9789 - val_loss: 0.1054 - val_acc: 0.9771\n",
      "Epoch 45/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.0726 - acc: 0.9789 - val_loss: 0.1051 - val_acc: 0.9771\n",
      "Epoch 46/50\n",
      "299/299 [==============================] - 13s 44ms/step - loss: 0.0722 - acc: 0.9789 - val_loss: 0.1048 - val_acc: 0.9771\n",
      "Epoch 47/50\n",
      "299/299 [==============================] - 13s 45ms/step - loss: 0.0719 - acc: 0.9789 - val_loss: 0.1044 - val_acc: 0.9771\n",
      "Epoch 48/50\n",
      "299/299 [==============================] - 13s 45ms/step - loss: 0.0716 - acc: 0.9789 - val_loss: 0.1042 - val_acc: 0.9771\n",
      "Epoch 49/50\n",
      "299/299 [==============================] - 13s 45ms/step - loss: 0.0713 - acc: 0.9789 - val_loss: 0.1039 - val_acc: 0.9771\n",
      "Epoch 50/50\n",
      "299/299 [==============================] - 13s 45ms/step - loss: 0.0710 - acc: 0.9789 - val_loss: 0.1040 - val_acc: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e2124f1e50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03f1196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Always remember to save the weights\n",
    "\n",
    "model.save_weights('etu_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f7c7d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the weights, if you close the application\n",
    "\n",
    "model.load_weights('etu_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b539c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference Setup\n",
    "\n",
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07679d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decode sample sequeces\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea36e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ba5f82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Input English sentence: im glad to see you again\n",
      "Actual Urdu Translation:  mai app ko dobara dekh kar khush hun \n",
      "Predicted Urdu Translation:  mai app ko dobara dekh kar khush hun \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Urdu Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Urdu Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f21e9f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['mai', 'app', 'ko', 'dobara', 'dekh', 'kar', 'khush', 'hun']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [\n",
    "    y_train[k:k+1].values[0][6:-4].split()\n",
    "]\n",
    "print(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7c1f005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mai', 'app', 'ko', 'dobara', 'dekh', 'kar', 'khush', 'hun']\n",
      "BLEU score -> 1.0\n"
     ]
    }
   ],
   "source": [
    "candidate = decoded_sentence[:-4].split()\n",
    "print(candidate)\n",
    "print('BLEU score -> {}'.format(sentence_bleu(reference, candidate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91f32316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Input English sentence: look who its\n",
      "Actual Urdu Translation:  dekho kon hai \n",
      "Predicted Urdu Translation:  dekho kon hai \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Urdu Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Urdu Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6eb0cfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dekho', 'kon', 'hai']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [\n",
    "    y_train[k:k+1].values[0][6:-4].split()\n",
    "]\n",
    "print(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19a930cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score -> 1.2213386697554703e-77\n"
     ]
    }
   ],
   "source": [
    "candidate = decoded_sentence[:-4].split()\n",
    "print('BLEU score -> {}'.format(sentence_bleu(reference, candidate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f10f3e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Input English sentence: happy to meet you\n",
      "Actual Urdu Translation:  aap se mil ke khushi hui \n",
      "Predicted Urdu Translation:  aap se mil ke khushi hui \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Urdu Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Urdu Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "47c6ae5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['aap', 'se', 'mil', 'ke', 'khushi', 'hui']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [\n",
    "    y_train[k:k+1].values[0][6:-4].split()\n",
    "]\n",
    "print(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56161fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aap', 'se', 'mil', 'ke', 'khushi', 'hui']\n",
      "BLEU score -> 1.0\n"
     ]
    }
   ],
   "source": [
    "candidate = decoded_sentence[:-4].split()\n",
    "print(candidate)\n",
    "print('BLEU score -> {}'.format(sentence_bleu(reference, candidate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "56651792",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f9fce066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Input English sentence: do you have some place\n",
      "Actual Urdu Translation:  kiya aap ke paas koi jagah hai \n",
      "Predicted Urdu Translation:  kiya aap ke paas koi jagah hai \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(val_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_test[k:k+1].values[0])\n",
    "print('Actual Urdu Translation:', y_test[k:k+1].values[0][6:-4])\n",
    "print('Predicted Urdu Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3d92e88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['kiya', 'aap', 'ke', 'paas', 'koi', 'jagah', 'hai']]\n",
      "['kiya', 'aap', 'ke', 'paas', 'koi', 'jagah', 'hai']\n",
      "BLEU score -> 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [\n",
    "    y_test[k:k+1].values[0][6:-4].split()\n",
    "]\n",
    "print(reference)\n",
    "candidate = decoded_sentence[:-4].split()\n",
    "print(candidate)\n",
    "print('BLEU score -> {}'.format(sentence_bleu(reference, candidate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3e174f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Input English sentence: i would love to travel again\n",
      "Actual Urdu Translation:  mein dobara safar krna pasand krun ga \n",
      "Predicted Urdu Translation:  mein dobara safar krna pasand krun ga \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(val_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_test[k:k+1].values[0])\n",
    "print('Actual Urdu Translation:', y_test[k:k+1].values[0][6:-4])\n",
    "print('Predicted Urdu Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a149fd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['mein', 'dobara', 'safar', 'krna', 'pasand', 'krun', 'ga']]\n",
      "['mein', 'dobara', 'safar', 'krna', 'pasand', 'krun', 'ga']\n",
      "BLEU score -> 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [\n",
    "    y_test[k:k+1].values[0][6:-4].split()\n",
    "]\n",
    "print(reference)\n",
    "candidate = decoded_sentence[:-4].split()\n",
    "print(candidate)\n",
    "print('BLEU score -> {}'.format(sentence_bleu(reference, candidate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c2a74bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Input English sentence: good to see you\n",
      "Actual Urdu Translation:  tumhe dekh kar acha laga \n",
      "Predicted Urdu Translation:  tumhe dekh kar acha laga \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(val_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_test[k:k+1].values[0])\n",
    "print('Actual Urdu Translation:', y_test[k:k+1].values[0][6:-4])\n",
    "print('Predicted Urdu Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "44e1be12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['tumhe', 'dekh', 'kar', 'acha', 'laga']]\n",
      "['tumhe', 'dekh', 'kar', 'acha', 'laga']\n",
      "BLEU score -> 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [\n",
    "    y_test[k:k+1].values[0][6:-4].split()\n",
    "]\n",
    "print(reference)\n",
    "candidate = decoded_sentence[:-4].split()\n",
    "print(candidate)\n",
    "print('BLEU score -> {}'.format(sentence_bleu(reference, candidate)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
